{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cce60d7-aa29-46b9-9a9b-c19940aee89a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "genai.configure(api_key=os.getenv('GEMINI_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83b7ab0-58f5-4a08-ac16-d72d63c00f03",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Manual testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9c9a4dd6-74c2-4216-bb1a-46744a191b25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1734875778.299583 2220265 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sono afgano/afgana.\n",
      "\n",
      "\n",
      "* **Sono afgano:** if you are a male.\n",
      "* **Sono afgana:** if you are a female.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(\"gemini-1.5-pro\")\n",
    "response = model.generate_content(\"Can you translate the following sentence into Italian: I am Afghan.\",\n",
    "                                 generation_config=genai.types.GenerationConfig(\n",
    "                                                                                candidate_count=1,\n",
    "                                                                                temperature=1\n",
    "                                                                                )\n",
    "                                 )\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a1214a54-873e-4580-ae13-2e69aff1506e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are a few ways to translate \"I am Afghan\" into French, with slight nuances:\n",
      "\n",
      "* **Je suis afghan.** (Masculine) - This is the most direct and common translation if you are male.\n",
      "* **Je suis afghane.** (Feminine) - This is the correct translation if you are female.\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "* **Je suis:** This means \"I am\".\n",
      "* **afghan:** This is the masculine form of the\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(\"gemini-2.0-flash-exp\")\n",
    "response = model.generate_content(\"Can you translate the following sentence into French: I am Afghan.\",\n",
    "                                 generation_config=genai.types.GenerationConfig(\n",
    "                                                                                candidate_count=1,\n",
    "                                                                                temperature=0.4, \n",
    "                                                                                max_output_tokens=100\n",
    "                                                                                )\n",
    "                                 )\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bca3614b-d96d-44cf-8816-a216eb0956eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ich bin Afghanin/Afghane.\n",
      "\n",
      "* **Ich bin Afghanin:**  This is used by a female speaker.\n",
      "* **Ich bin Afghane:** This is used by a male speaker.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "response = model.generate_content(\"Can you translate the following sentence into German: I am Afghan.\",\n",
    "                                 generation_config=genai.types.GenerationConfig(\n",
    "                                                                                candidate_count=1,\n",
    "                                                                                temperature=1\n",
    "                                                                                )\n",
    "                                 )\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2733a374-a1d1-42e8-9162-090c46a19a23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soy afgano. (For a male speaker)\n",
      "Soy afgana. (For a female speaker)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "response = model.generate_content(\"Can you translate the following sentence into Spanish: I am Afghan.\",\n",
    "                                 generation_config=genai.types.GenerationConfig(\n",
    "                                                                                candidate_count=1,\n",
    "                                                                                temperature=1\n",
    "                                                                                )\n",
    "                                 )\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c856b8e-50e0-4c70-bc06-6fd7bb841b25",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7314431a-68e8-40aa-a3bf-04cf6a801378",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eng': {'m': None, 'f': None, 'n': 'I am Mauritanian.'},\n",
       " 'fra': {'m': 'Je suis Mauritanien.',\n",
       "  'f': 'Je suis Mauritanienne.',\n",
       "  'n': None},\n",
       " 'spa': {'m': 'Soy mauritano.', 'f': 'Soy mauritana.', 'n': None},\n",
       " 'deu': {'m': 'Ich bin Mauretanier.',\n",
       "  'f': 'Ich bin  Mauretanierin.',\n",
       "  'n': None},\n",
       " 'it': {'m': 'Sono mauritano.', 'f': 'Sono mauritaniana.', 'n': None}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "df = pd.read_csv('output/dataset.csv')\n",
    "df['sentence'] = df['sentence'].apply(lambda x: ast.literal_eval(x)) # str to dict\n",
    "df.iloc[120]['sentence']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d330d888-1151-499e-9aa5-c8071a14122b",
   "metadata": {},
   "source": [
    "# Experiment Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6a5fd9d-1d54-4c7b-8f6f-41b8d5db47cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "languages = {\n",
    "    'fra': 'French',\n",
    "    'spa': 'Spanish',\n",
    "    'deu': 'German',\n",
    "    'it': 'Italian'\n",
    "}\n",
    "# https://ai.google.dev/gemini-api/docs/models/gemini#gemini-2.0-flash\n",
    "models = [\"gemini-1.5-flash\", \"gemini-1.5-pro\", \"gemini-2.0-flash-exp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dc19991-618c-4d74-b325-65c33956828b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def experiment(model_name, lang_name, sentence):\n",
    "    '''\n",
    "    Translates a given sentence into the specified target language using the specified model.\n",
    "\n",
    "    Parameters:\n",
    "    - model (str): The name of the model to use .\n",
    "    - language (str): The target language for the translation.\n",
    "    - sentence (str): The sentence to be translated.\n",
    "\n",
    "    Returns:\n",
    "    - str: The translated sentence generated by the model.\n",
    "    '''\n",
    "    \n",
    "    model = genai.GenerativeModel(model_name)\n",
    "    response = model.generate_content(f\"Can you translate the following sentence into {lang_name}: {sentence}\",\n",
    "                                      generation_config=genai.types.GenerationConfig(temperature=0.2,\n",
    "                                                                                     top_p=1,\n",
    "                                                                                     max_output_tokens=100))\n",
    "    \n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55703dc5-5652-4943-a840-d859704f9b0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add progress bar functionality\n",
    "tqdm.pandas()\n",
    "\n",
    "def process_sentences(df, languages, models, output_folder):\n",
    "    \"\"\"\n",
    "    Processes sentences for multiple languages and models.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing sentences.\n",
    "        languages (dict): A dictionary where keys are language codes (e.g., 'fra', 'spa') \n",
    "                          and values are full language names (e.g., 'French', 'Spanish').\n",
    "        models (list): A list of model names to use for processing.\n",
    "        output_folder (str): The folder to save output CSV files.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    for model_name in models:\n",
    "        for lang_code, lang_name in languages.items():\n",
    "            # Create a new DataFrame for the current language\n",
    "            df_exp = pd.DataFrame(columns=['eng', f'{lang_code}_m', f'{lang_code}_f', f'{lang_code}_n', 'output'])\n",
    "            df_exp['eng'] = df['sentence'].apply(lambda x: x.get('eng', {}).get('n'))\n",
    "            df_exp[f'{lang_code}_m'] = df['sentence'].apply(lambda x: x.get(lang_code, {}).get('m'))\n",
    "            df_exp[f'{lang_code}_f'] = df['sentence'].apply(lambda x: x.get(lang_code, {}).get('f'))\n",
    "            df_exp[f'{lang_code}_n'] = df['sentence'].apply(lambda x: x.get(lang_code, {}).get('n'))\n",
    "\n",
    "            # Apply the experiment function\n",
    "            df_exp['output'] = df_exp['eng'].progress_apply(lambda sentence: experiment(model_name, lang_name, sentence))\n",
    "\n",
    "            # Save the results to a CSV file\n",
    "            output_path = f\"{output_folder}/{lang_code}_{model_name.split('gemini-')[1]}_exp.csv\"\n",
    "            df_exp.to_csv(output_path, index=False)\n",
    "            print(f\"Saved results to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "648e3726-e651-4603-be99-fcd49dbc85f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 193/193 [02:13<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to output/gemini/fra_1.5-flash_exp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 193/193 [02:03<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to output/gemini/spa_1.5-flash_exp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 193/193 [01:59<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to output/gemini/deu_1.5-flash_exp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 193/193 [01:57<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to output/gemini/it_1.5-flash_exp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "process_sentences(df, languages, [models[0]], output_folder='output/gemini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e9b7026-0cff-455b-9cbe-c04322ba836b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 193/193 [03:40<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to output/gemini/fra_1.5-pro_exp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 193/193 [04:22<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to output/gemini/spa_1.5-pro_exp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 193/193 [05:17<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to output/gemini/deu_1.5-pro_exp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 193/193 [04:05<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to output/gemini/it_1.5-pro_exp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "process_sentences(df, languages, [models[1]], output_folder='output/gemini')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
